# Day 3: ZFS æ ¸å¿ƒæ¦‚å¿µä¸å­˜å‚¨æ± ç®¡ç†

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- **ç†è®ºæ·±åº¦**: æ·±å…¥ç†è§£ ZFS çš„æ ¸å¿ƒæ¶æ„ï¼ŒåŒ…æ‹¬ vdev (è™šæ‹Ÿè®¾å¤‡)ã€zpool (å­˜å‚¨æ± ) å’Œ dataset (æ•°æ®é›†) ä¹‹é—´çš„å…³ç³»ã€‚
- **æ ¸å¿ƒæŠ€èƒ½**: ç†Ÿç»ƒæŒæ¡ `zpool` å’Œ `zfs` å‘½ä»¤è¡Œå·¥å…·ï¼Œèƒ½å¤Ÿç‹¬ç«‹åˆ›å»ºã€ç®¡ç†ã€ç›‘æ§ ZFS å­˜å‚¨æ± å’Œæ•°æ®é›†ã€‚
- **å…³é”®ç‰¹æ€§**: ç†è§£ ZFS çš„å†™æ—¶å¤åˆ¶ (Copy-on-Write)ã€ç«¯åˆ°ç«¯æ•°æ®æ ¡éªŒ (Checksum) å’Œè‡ªä¿®å¤ (Self-Healing) æœºåˆ¶çš„åŸç†ä¸ä»·å€¼ã€‚
- **Go ç¼–ç¨‹å®è·µ**: å¼€å§‹ç¼–å†™ä¸€ä¸ª Go ç¨‹åºï¼Œç”¨äºè°ƒç”¨ ZFS å‘½ä»¤å¹¶è§£æè¾“å‡ºï¼Œå®ç°å¯¹ ZFS å­˜å‚¨æ± å¥åº·çŠ¶å†µå’Œå®¹é‡çš„åŸºç¡€ç›‘æ§ã€‚

## ğŸ“š ç†è®ºåŸºç¡€ (40%)

### 1. ZFS æ¶æ„è§£æ

ZFS ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†æ–‡ä»¶ç³»ç»Ÿå’Œå·ç®¡ç†çš„ä¼ ç»Ÿæ¨¡å¼ï¼Œå°†äºŒè€…åˆä¸ºä¸€ä½“ã€‚å…¶åˆ†å±‚æ¶æ„æ˜¯ç†è§£ ZFS çš„å…³é”®ã€‚

#### a. vdev (Virtual Device - è™šæ‹Ÿè®¾å¤‡)
vdev æ˜¯ ZFS å­˜å‚¨æ± çš„æ„å»ºåŸºçŸ³ï¼Œæ˜¯ç‰©ç†ç£ç›˜çš„æŠ½è±¡å±‚ã€‚ä¸€ä¸ªæˆ–å¤šä¸ªç‰©ç†ç£ç›˜ï¼ˆæˆ–åˆ†åŒºã€æ–‡ä»¶ï¼‰å¯ä»¥ç»„æˆä¸€ä¸ª vdevã€‚vdev å†³å®šäº†å…¶å†…éƒ¨æ•°æ®çš„å†—ä½™çº§åˆ«ã€‚å¸¸è§çš„ vdev ç±»å‹åŒ…æ‹¬ï¼š
- **å•ä¸ªç£ç›˜ (disk)**: æ— å†—ä½™ï¼Œä¸æ¨èç”¨äºç”Ÿäº§ã€‚
- **é•œåƒ (mirror)**: ç±»ä¼¼ RAID 1ï¼Œæä¾›æœ€é«˜çš„æ•°æ®å†—ä½™ã€‚
- **raidz1/raidz2/raidz3**: ç±»ä¼¼ RAID 5/6ï¼Œåˆ†åˆ«å¯ä»¥å®¹å¿ 1/2/3 ä¸ªç£ç›˜æ•…éšœã€‚å®ƒé€šè¿‡å¯å˜å®½åº¦çš„æ¡å¸¦è§£å†³äº† RAID çš„â€œå†™æ´â€é—®é¢˜ã€‚
- **çƒ­å¤‡ (hot spare)**: ç”¨äºè‡ªåŠ¨æ›¿æ¢æ•…éšœç£ç›˜çš„å¤‡ç”¨ç›˜ã€‚
- **ç‰¹æ®Š vdev**:
    - **log (ZIL/SLOG)**: ç”¨äºåŠ é€ŸåŒæ­¥å†™å…¥æ“ä½œçš„ç‹¬ç«‹è®¾å¤‡ï¼Œé€šå¸¸æ˜¯é«˜é€Ÿ SSDã€‚
    - **cache (L2ARC)**: ç”¨ä½œäºŒçº§è¯»ç¼“å­˜çš„è®¾å¤‡ï¼Œé€šå¸¸æ˜¯é«˜é€Ÿ SSDã€‚

#### b. zpool (Storage Pool - å­˜å‚¨æ± )
zpool æ˜¯ç”±ä¸€ä¸ªæˆ–å¤šä¸ª vdev æ„æˆçš„ç»Ÿä¸€å­˜å‚¨èµ„æºæ± ã€‚å®ƒæ˜¯ ZFS ä¸­æœ€å¤§çš„å­˜å‚¨å•å…ƒã€‚
- **ç‰¹æ€§**:
    - **ç»Ÿä¸€ç®¡ç†**: ä¸€ä¸ª zpool å°†æ‰€æœ‰ vdev çš„å®¹é‡æ•´åˆåœ¨ä¸€èµ·ï¼Œå¯¹å¤–æä¾›ä¸€ä¸ªå·¨å¤§çš„å­˜å‚¨ç©ºé—´ã€‚
    - **æ‰©å±•æ€§**: å¯ä»¥é€šè¿‡å‘ zpool ä¸­æ·»åŠ æ–°çš„ vdev æ¥åŠ¨æ€æ‰©å®¹ï¼ˆä½†ä¸èƒ½å‘å·²æœ‰çš„ vdev ä¸­æ·»åŠ ç£ç›˜ï¼‰ã€‚
    - **å†—ä½™æ€§**: zpool çš„å†—ä½™æ€§ç”±å…¶åŒ…å«çš„ vdev å†³å®šã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç”±ä¸¤ä¸ª mirror vdev ç»„æˆçš„ zpoolï¼Œå¯ä»¥å®¹å¿æ¯ä¸ª mirror vdev ä¸­å„åä¸€å—ç›˜ã€‚

#### c. dataset (æ•°æ®é›†)
dataset æ˜¯ä» zpool ä¸­åˆ’åˆ†å‡ºæ¥çš„ã€å¯ä»¥ç‹¬ç«‹æŒ‚è½½å’Œç®¡ç†çš„æ–‡ä»¶ç³»ç»Ÿã€‚è¿™æ˜¯ç”¨æˆ·ä¸ ZFS äº¤äº’çš„ä¸»è¦å±‚é¢ã€‚
- **ç‰¹æ€§**:
    - **è½»é‡çº§**: åˆ›å»ºå’Œé”€æ¯æ•°æ®é›†å‡ ä¹æ˜¯ç¬æ—¶å®Œæˆçš„ã€‚
    - **ç²¾ç»†åŒ–ç®¡ç†**: å¯ä»¥ä¸ºæ¯ä¸ªæ•°æ®é›†è®¾ç½®ç‹¬ç«‹çš„å±æ€§ï¼Œå¦‚æŒ‚è½½ç‚¹ã€é…é¢ (quota)ã€é¢„ç•™ç©ºé—´ (reservation)ã€å‹ç¼©ç®—æ³• (compression)ã€è®°å½•å¤§å° (recordsize) ç­‰ã€‚
    - **å±æ€§ç»§æ‰¿**: å­æ•°æ®é›†ä¼šè‡ªåŠ¨ç»§æ‰¿çˆ¶æ•°æ®é›†çš„å±æ€§ï¼Œä¾¿äºç»Ÿä¸€ç®¡ç†ã€‚
- **zvol**: é™¤äº†æ–‡ä»¶ç³»ç»Ÿï¼ŒZFS è¿˜å¯ä»¥åˆ›å»ºå—è®¾å¤‡ï¼Œç§°ä¸º zvolï¼Œå¯ç”¨äº iSCSIã€è™šæ‹Ÿæœºç£ç›˜ç­‰åœºæ™¯ã€‚

### 2. ZFS å…³é”®æ•°æ®ä¿æŠ¤æœºåˆ¶

#### a. å†™æ—¶å¤åˆ¶ (Copy-on-Write, CoW)
è¿™æ˜¯ ZFS çš„æ ¸å¿ƒæœºåˆ¶ã€‚ZFS ä»ä¸è¦†ç›–å†™ï¼ˆOverwriteï¼‰æ—§æ•°æ®ã€‚å½“æ•°æ®éœ€è¦ä¿®æ”¹æ—¶ï¼Œå®ƒä¼šå°†ä¿®æ”¹åçš„æ–°æ•°æ®å†™å…¥åˆ°ä¸€å—æ–°çš„ç©ºé—²ä½ç½®ï¼Œç„¶åæ›´æ–°æŒ‡å‘è¯¥æ•°æ®çš„å…ƒæ•°æ®æŒ‡é’ˆã€‚
- **ä¼˜ç‚¹**:
    - **æ— å†™æ´**: ç£ç›˜ä¸Šçš„æ•°æ®çŠ¶æ€æ°¸è¿œæ˜¯ä¸€è‡´çš„ã€‚å¦‚æœåœ¨å†™å…¥è¿‡ç¨‹ä¸­æ–­ç”µï¼Œæ—§æ•°æ®ä¾ç„¶å®Œå¥½æ— æŸï¼Œæ–°æ•°æ®åªæ˜¯æœªè¢«å¼•ç”¨çš„åƒåœ¾ç©ºé—´ã€‚
    - **å»‰ä»·çš„å¿«ç…§**: åˆ›å»ºå¿«ç…§åªéœ€å¤åˆ¶ä¸€ä»½å…ƒæ•°æ®æŒ‡é’ˆï¼Œå‡ ä¹ä¸å ç”¨ç©ºé—´å’Œæ—¶é—´ã€‚

#### b. ç«¯åˆ°ç«¯æ•°æ®æ ¡éªŒ (End-to-end Checksum)
- **å·¥ä½œåŸç†**: å½“æ•°æ®å—å†™å…¥æ—¶ï¼ŒZFS ä¼šè®¡ç®—å…¶æ ¡éªŒå’Œï¼ˆå¦‚ SHA-256ï¼‰å¹¶ä¸æ•°æ®å—çš„å…ƒæ•°æ®æŒ‡é’ˆä¸€åŒå­˜å‚¨ã€‚å½“æ•°æ®å—è¢«è¯»å–æ—¶ï¼ŒZFS ä¼šé‡æ–°è®¡ç®—æ ¡éªŒå’Œå¹¶ä¸å­˜å‚¨çš„å€¼è¿›è¡Œæ¯”å¯¹ã€‚
- **ä»·å€¼**: èƒ½å¤Ÿæ£€æµ‹åˆ°â€œé™é»˜æ•°æ®æŸåâ€ï¼ˆSilent Data Corruptionï¼‰ï¼Œå³æ•°æ®åœ¨ç£ç›˜ä¸Šå› ä»‹è´¨è€åŒ–ç­‰åŸå› å‘ç”Ÿä½ç¿»è½¬ï¼Œè€Œç¡¬ä»¶å¹¶æœªæŠ¥ï¿½ï¿½ä»»ä½•é”™è¯¯ã€‚

#### c. æ•°æ®è‡ªä¿®å¤ (Self-Healing)
- **å·¥ä½œåŸç†**: åœ¨ä¸€ä¸ªå†—ä½™çš„ zpool (mirror æˆ– raidz) ä¸­ï¼Œå¦‚æœè¯»å–æ•°æ®æ—¶å‘ç°æ ¡éªŒå’Œä¸åŒ¹é…ï¼ŒZFS ä¼šåˆ¤å®šæ•°æ®æŸåã€‚æ­¤æ—¶ï¼Œå®ƒä¼šåˆ©ç”¨å…¶ä»–ç£ç›˜ä¸Šçš„å†—ä½™ä¿¡æ¯ï¼ˆé•œåƒæ•°æ®æˆ–å¥‡å¶æ ¡éªŒï¼‰æ¥é‡å»ºæ­£ç¡®çš„æ•°æ®ï¼Œä¿®å¤æŸåçš„å—ï¼Œå¹¶å°†æ­£ç¡®çš„æ•°æ®è¿”å›ç»™åº”ç”¨ç¨‹åºï¼Œæ•´ä¸ªè¿‡ç¨‹å¯¹ç”¨æˆ·é€æ˜ã€‚

## ğŸ› ï¸ å®è·µæ“ä½œ (40%)

### 1. ZFS ç¯å¢ƒå‡†å¤‡
```bash
# åœ¨ Debian/Ubuntu ä¸Šå®‰è£… ZFS
sudo apt-get update
sudo apt-get install -y zfsutils-linux

# ç¡®è®¤ ZFS å†…æ ¸æ¨¡å—å·²åŠ è½½
lsmod | grep zfs

# ä½¿ç”¨å‰ä¸€å¤©çš„ loop è®¾å¤‡è¿›è¡Œå®éªŒ
# ç¡®ä¿å®ƒä»¬æ˜¯å¹²å‡€çš„
sudo mdadm --stop /dev/md* || true
sudo wipefs -a /dev/loop* # æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ—§å…ƒæ•°æ®
ls /dev/loop{1..8}
```

### 2. åˆ›å»ºå’Œç®¡ç† ZFS å­˜å‚¨æ±  (`zpool`)

#### a. åˆ›å»ºé•œåƒæ±  (Mirror Pool)
```bash
# ä½¿ç”¨ /dev/loop1 å’Œ /dev/loop2 åˆ›å»ºä¸€ä¸ªåä¸º 'tank' çš„é•œåƒæ± 
# tank æ˜¯ ZFS ç¤¾åŒºå¸¸ç”¨çš„ç¤ºä¾‹æ± å
sudo zpool create tank mirror /dev/loop1 /dev/loop2

# æŸ¥çœ‹æ± çŠ¶æ€
sudo zpool status tank
# é‡ç‚¹å…³æ³¨ state: ONLINE, scan: none requested, errors: No known data errors
# config éƒ¨åˆ†ä¼šæ˜¾ç¤º tank ç”±ä¸€ä¸ª mirror-0 vdev æ„æˆ
```

#### b. åˆ›å»º raidz æ±  (raidz1 Pool)
```bash
# ä½¿ç”¨ /dev/loop3, loop4, loop5 åˆ›å»ºä¸€ä¸ªåä¸º 'datapool' çš„ raidz1 æ± 
sudo zpool create datapool raidz /dev/loop3 /dev/loop4 /dev/loop5

# æŸ¥çœ‹æ‰€æœ‰æ± çš„åˆ—è¡¨å’ŒåŸºæœ¬å®¹é‡ä¿¡æ¯
sudo zpool list
# NAME       SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
# datapool  2.88G   108K  2.88G        -         -     0%     0%  1.00x    ONLINE  -
# tank      1.94G   108K  1.94G        -         -     0%     0%  1.00x    ONLINE  -
```

#### c. é”€æ¯å­˜å‚¨æ± 
```bash
# é”€æ¯æ± ä¼šåˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œè¯·è°¨æ…æ“ä½œï¼
sudo zpool destroy datapool

# éªŒè¯æ± å·²è¢«é”€æ¯
sudo zpool list
```

### 3. åˆ›å»ºå’Œç®¡ç†æ•°æ®é›† (`zfs`)

#### a. åˆ›å»ºæ•°æ®é›†
é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ›å»º zpool æ—¶ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªåŒåçš„æ•°æ®é›†ï¼Œå¹¶æŒ‚è½½åˆ° `/<pool_name>`ã€‚
```bash
# åœ¨ tank æ± ä¸­åˆ›å»ºä¸€ä¸ªåä¸º 'data' çš„æ•°æ®é›†
sudo zfs create tank/data

# åˆ›å»ºä¸€ä¸ªåµŒå¥—çš„æ•°æ®é›†
sudo zfs create tank/data/project_a
```

#### b. æŸ¥çœ‹å’ŒæŒ‚è½½æ•°æ®é›†
```bash
# æŸ¥çœ‹ ZFS æ–‡ä»¶ç³»ç»Ÿåˆ—è¡¨
sudo zfs list
# NAME                  USED  AVAIL     REFER  MOUNTPOINT
# tank                  156K  1.85G     24.0K  /tank
# tank/data            48.0K  1.85G     24.0K  /tank/data
# tank/data/project_a  24.0K  1.85G     24.0K  /tank/data/project_a

# éªŒè¯æŒ‚è½½ç‚¹
df -h /tank/data
```

#### c. è®¾ç½®æ•°æ®é›†å±æ€§
```bash
# ä¸º project_a æ•°æ®é›†å¼€å¯ lz4 å‹ç¼©
sudo zfs set compression=lz4 tank/data/project_a

# ä¸º project_a è®¾ç½® 500MB çš„ç©ºé—´é…é¢
sudo zfs set quota=500M tank/data/project_a

# æŸ¥çœ‹ç‰¹å®šæ•°æ®é›†çš„æ‰€æœ‰å±æ€§
sudo zfs get all tank/data/project_a | grep -E 'compression|quota'
# NAME                 PROPERTY     VALUE     SOURCE
# tank/data/project_a  compression  lz4       local
# tank/data/project_a  quota        500M      local
```

## ğŸ’» Go ç¼–ç¨‹å®ç° (20%)

æˆ‘ä»¬ç¼–å†™ä¸€ä¸ª Go ç¨‹åºæ¥æ£€æŸ¥æ‰€æœ‰ ZFS æ± çš„å¥åº·çŠ¶å†µï¼Œå¹¶åˆ—å‡ºå®ƒä»¬çš„åŸºæœ¬ä¿¡æ¯ã€‚æˆ‘ä»¬å°†åˆ©ç”¨ ZFS å‘½ä»¤ä¸ºè„šæœ¬è®¾è®¡çš„å¯è§£æè¾“å‡ºæ ¼å¼ã€‚

**`zfs_checker.go`**
```go
package main

import (
	"fmt"
	"log"
	"os/exec"
	"strings"
)

// checkPoolsHealth uses `zpool status -x` to get a global health check.
// This command is designed for scripts: it outputs "all pools are healthy" on success.
func checkPoolsHealth() (string, error) {
	cmd := exec.Command("sudo", "zpool", "status", "-x")
	out, err := cmd.CombinedOutput()
	if err != nil {
        // If the command fails, it usually means a pool is unhealthy.
        // The output will contain the details.
		return strings.TrimSpace(string(out)), nil
	}
	return strings.TrimSpace(string(out)), nil
}

// listPoolsInfo uses `zpool list` with script-friendly options.
// -p: gives full numbers for sizes (parsable)
// -H: no headers
// -o: specify columns
func listPoolsInfo() (string, error) {
	cmd := exec.Command("sudo", "zpool", "list", "-p", "-H", "-o", "name,size,alloc,free,health")
	out, err := cmd.CombinedOutput()
	if err != nil {
		return "", fmt.Errorf("failed to list zpools: %w\nOutput: %s", err, string(out))
	}
	return string(out), nil
}

func main() {
	fmt.Println("--- ZFS Global Health Status ---")
	health, err := checkPoolsHealth()
	if err != nil {
		log.Fatalf("Error checking health: %v", err)
	}
	fmt.Println(health)
	fmt.Println("--------------------------------")

	fmt.Println("\n--- ZFS Pool Details (bytes) ---")
	fmt.Println("Name\tSize\tAlloc\tFree\tHealth")
	details, err := listPoolsInfo()
	if err != nil {
		log.Fatalf("Error listing pools: %v", err)
	}
	fmt.Println(details)
	fmt.Println("--------------------------------")
}
```

**å¦‚ä½•è¿è¡Œ:**
1. ä¿å­˜ä»£ç ä¸º `zfs_checker.go`ã€‚
2. æ‰§è¡Œ `go run zfs_checker.go`ã€‚
3. ç¨‹åºå°†é¦–å…ˆç»™å‡ºä¸€ä¸ªæ€»ä½“çš„å¥åº·ç»“è®ºï¼Œç„¶ååˆ—å‡ºæ¯ä¸ªæ± çš„è¯¦ç»†å®¹é‡å’Œå¥åº·çŠ¶æ€ã€‚

## ğŸ” æ•…éšœæ’æŸ¥ä¸ä¼˜åŒ–
- **æœ€ä½³å®è·µ**:
    - **ç¦ç”¨ç¡¬ä»¶ RAID**: æ°¸è¿œä¸è¦åœ¨ç¡¬ä»¶ RAID å¡ä¸Šåˆ›å»º ZFSï¼Œè®© ZFS ç›´æ¥ç®¡ç†è£¸ç›˜ï¼ˆJBOD æ¨¡å¼ï¼‰ï¼Œè¿™æ · ZFS æ‰èƒ½å®Œå…¨å‘æŒ¥å…¶æ•°æ®æ ¡éªŒå’Œä¿®å¤åŠŸèƒ½ã€‚
    - **ä½¿ç”¨æ•´ç›˜**: æ¨èå°†æ•´ä¸ªç£ç›˜ï¼ˆå¦‚ `/dev/sdb`ï¼‰è€Œä¸æ˜¯åˆ†åŒºï¼ˆå¦‚ `/dev/sdb1`ï¼‰äº¤ç»™ ZFSï¼Œè¿™æ ·å¯ä»¥è·å¾—æœ€ä½³æ€§èƒ½å’Œå¯é æ€§ã€‚
    - **æ± æ‰©å®¹**: ZFS æ± åªèƒ½é€šè¿‡æ·»åŠ æ–°çš„ vdev æ¥æ‰©å®¹ã€‚ä¾‹å¦‚ï¼Œå‘ä¸€ä¸ªå·²æœ‰çš„ mirror pool ä¸­å†æ·»åŠ ä¸€ä¸ª mirror vdevã€‚ä½ ä¸èƒ½å‘ä¸€ä¸ªå·²æœ‰çš„ mirror vdev ä¸­æ·»åŠ ç¬¬ä¸‰å—ç›˜ã€‚
- **å¸¸è§çŠ¶æ€**:
    - **`DEGRADED`**: æ± ä¸­æŸä¸ª vdev å¤±å»äº†ä¸€éƒ¨åˆ†å†—ä½™ï¼ˆå¦‚ mirror ä¸­åäº†ä¸€å—ç›˜ï¼‰ï¼Œæ± ä»åœ¨çº¿å¯ç”¨ï¼Œä½†åº”å°½å¿«æ›¿æ¢æ•…éšœè®¾å¤‡ã€‚
    - **`FAULTED`**: æ± ä¸­æŸä¸ª vdev å®Œå…¨æŸåï¼ˆå¦‚ raidz1 ä¸­åäº†ä¸¤å—ç›˜ï¼‰ï¼Œæ± å·²ç¦»çº¿ï¼Œæ•°æ®æ— æ³•è®¿é—®ã€‚éœ€è¦ä»å¤‡ä»½ä¸­æ¢å¤ã€‚

## ğŸ“ å®æˆ˜é¡¹ç›®
1. **è®¾è®¡å¹¶åˆ›å»ºå­˜å‚¨å¸ƒå±€**:
   - é”€æ¯ç°æœ‰çš„ `tank` æ± ã€‚
   - é‡æ–°åˆ›å»ºä¸€ä¸ªåä¸º `homeserver` çš„æ–°æ± ã€‚
   - è¯¥æ± åº”åŒ…å«ä¸¤ä¸ª vdevï¼š
     - ä¸€ä¸ªåä¸º `vdev_docs` çš„ mirror vdevï¼Œä½¿ç”¨ `/dev/loop1` å’Œ `/dev/loop2`ï¼Œç”¨äºå­˜æ”¾å…³é”®æ–‡æ¡£ã€‚
     - ä¸€ä¸ªåä¸º `vdev_media` çš„ raidz1 vdevï¼Œä½¿ç”¨ `/dev/loop3`, `/dev/loop4`, `/dev/loop5`ï¼Œç”¨äºå­˜æ”¾åª’ä½“æ–‡ä»¶ã€‚
   - **å‘½ä»¤æç¤º**: `sudo zpool create homeserver mirror /dev/loop1 /dev/loop2 raidz /dev/loop3 /dev/loop4 /dev/loop5`
2. **åˆ›å»ºå’Œé…ç½®æ•°æ®é›†**:
   - åœ¨ `homeserver` æ± ä¸­åˆ›å»º `documents` å’Œ `media` ä¸¤ä¸ªæ•°æ®é›†ã€‚
   - ä¸º `documents` æ•°æ®é›†å¼€å¯ `lz4` å‹ç¼©ã€‚
   - ä¸º `media` æ•°æ®é›†è®¾ç½® `recordsize=1M`ï¼ˆå¤§æ–‡ä»¶å­˜å‚¨çš„æ¨èä¼˜åŒ–ï¼‰ã€‚
   - ä¸º `documents` æ•°æ®é›†è®¾ç½® `100M` çš„é…é¢ã€‚
3. **éªŒè¯**: ä½¿ç”¨ `zpool status`, `zfs list`, `zfs get all` ç­‰å‘½ä»¤éªŒè¯ä½ çš„é…ç½®æ˜¯å¦æ­£ç¡®ã€‚

## ğŸ  è¯¾åä½œä¸š
1. **å®˜æ–¹æ–‡æ¡£é˜…è¯»**: é˜…è¯» OpenZFS å®˜æ–¹æ–‡æ¡£ä¸­å…³äº `zpool` å’Œ `zfs` å‘½ä»¤çš„ä»‹ç»ï¼Œäº†è§£æ›´å¤šé«˜çº§é€‰é¡¹ã€‚
2. **æ–¹æ¡ˆè®¾è®¡**: ä¸ºä¸€ä¸ªéœ€è¦é«˜å¯ç”¨æ€§çš„å°å‹ä¼ä¸šæ•°æ®åº“æœåŠ¡å™¨è®¾è®¡ä¸€ä¸ª ZFS å­˜å‚¨æ± å¸ƒå±€æ–¹æ¡ˆã€‚ä½ éœ€è¦è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ï¼š
   - ä½¿ç”¨å“ªç§ vdev ç±»å‹ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
   - æ˜¯å¦éœ€è¦ç‹¬ç«‹çš„ log (SLOG) è®¾å¤‡ï¼Ÿå¦‚æœéœ€è¦ï¼Œæ¨èä»€ä¹ˆç¡¬ä»¶ï¼Ÿ
   - å¤‡ä»½ç­–ç•¥å¦‚ä½•ä¸ ZFS çš„å¿«ç…§åŠŸèƒ½ç»“åˆï¼Ÿ
   - å°†ä½ çš„è®¾è®¡æ–¹æ¡ˆå’Œç†ç”±å†™æˆä¸€ä»½ç®€è¦çš„ Markdown æ–‡æ¡£ã€‚
3. **ç¯å¢ƒæ¸…ç†**:
   ```bash
   sudo zfs destroy -r homeserver || true
   sudo zpool destroy tank || true
   sudo losetup -d /dev/loop*
   ```
